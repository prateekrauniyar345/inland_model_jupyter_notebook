{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import tempfile\n",
    "import fiona\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import traceback\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# get the shapefile folder\n",
    "shapefile_folder = os.path.join(cwd, 'shapefile')\n",
    "\n",
    "# Pattern to match shapefile (shapefile typically have extensions like .shp)\n",
    "shapefile_pattern = os.path.join(shapefile_folder, '*.shp')\n",
    "# Get the list of all shapefile in the folder\n",
    "shapefiles_list = glob.glob(shapefile_pattern)\n",
    "\n",
    "# Count the number of shapefile\n",
    "num_shapefiles = len(shapefiles_list)\n",
    "\n",
    "# get the java folder\n",
    "java_folder = os.path.join(cwd, 'source/java')\n",
    "\n",
    "# get the csv folder\n",
    "csv_folder = os.path.join(cwd, 'source/csv_files')\n",
    "\n",
    "# get the raster file\n",
    "raster_folder = os.path.join(cwd,'source/rasters')\n",
    "tiffile = os.path.join(raster_folder,'raster.tif')\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(out_image, csv_folder, index, parameters, csv_files, stand_id ):\n",
    "        \"\"\"\n",
    "        Process the raster file and save the band data to CSV files for each shape.\n",
    "\n",
    "        Parameters:\n",
    "        - out_image (numpy array): Masked raster data.\n",
    "        - model_parameters (dict): Dictionary containing shape parameters.\n",
    "        - output_folder (str): Folder to save the CSV files.\n",
    "        Returns:\n",
    "        - List of CSV filenames.\n",
    "        \"\"\"     \n",
    "        os.makedirs(csv_folder, exist_ok=True)\n",
    "        column_names = ['aws0_100', 'DEP2RES', 'HeatLoad', 'MAPMCMT', 'Rad_sm', 'B_TD', 'soc_05','soc0_20','slope','pratio','consLITH']\n",
    "        with rasterio.open(tiffile) as src:\n",
    "            # Flatten band data and create DataFrame\n",
    "            band_data = {f'band_{j+1}': out_image[j].flatten() for j in range(out_image.shape[0])}\n",
    "            df = pd.DataFrame(band_data)\n",
    "            # Replace the nodata values with NaN\n",
    "            for band in band_data:\n",
    "                df[band] = df[band].replace(src.nodata, np.nan)\n",
    "            # Drop rows with NaN values\n",
    "            df_cleaned = df.dropna(how='any')\n",
    "            if not df_cleaned.empty:\n",
    "                # Drop columns that contain any NaN values\n",
    "                df_cleaned = df_cleaned.dropna(axis=1, how='any')\n",
    "                # Rename columns\n",
    "                if len(column_names) >= df_cleaned.shape[1]:\n",
    "                    df_cleaned.columns = column_names[:df_cleaned.shape[1]]\n",
    "                # Extend the csv file with the model parameters\n",
    "                param_df = pd.DataFrame({key: [value[0]] * len(df_cleaned) for key, value in parameters.items()})\n",
    "                param_df = param_df.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "                df_extended = pd.concat([df_cleaned, param_df], axis=1)\n",
    "                # Again drop the NaN values\n",
    "                df_extended = df_extended.dropna()\n",
    "                # Save to CSV\n",
    "                csv_filename = f\"csv_for_stand_{stand_id}.csv\"\n",
    "                csv_path = os.path.join(csv_folder, csv_filename)\n",
    "                csv_files.append(csv_path)\n",
    "                df_extended.to_csv(csv_path, index=False)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# csvfile list\n",
    "csv_files = []\n",
    "# Define desired columns\n",
    "desired_columns = ['QMD', 'RC_PROP', 'WH_PROP', 'GF_PROP', 'LP_PROP', 'WL_PROP', 'DF_PROP', 'PP_PROP']\n",
    "stand_id = []\n",
    "# Ensure the output directory exists and remove all existing CSV files in the output folder\n",
    "if os.path.exists(csv_folder):\n",
    "    for file in glob.glob(os.path.join(csv_folder, '*.csv')):\n",
    "        os.remove(file)\n",
    "else:\n",
    "    os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for shapefile in shapefiles_list:\n",
    "    # Path to your shapefile\n",
    "    shapefile_path = shapefile\n",
    "    # Read the main shapefile\n",
    "    try:\n",
    "        ply = gpd.read_file(shapefile_path)\n",
    "    except Exception as ex:\n",
    "        print(f\"Unable to read shapefile  {shapefile_path}. Your file may be corrupt: {ex}\")\n",
    "        raise\n",
    "\n",
    "    # Change CRS to match raster\n",
    "    ply = ply.to_crs(epsg=3857)\n",
    "    with tempfile.NamedTemporaryFile() as tf:\n",
    "        crsName = tf.name\n",
    "    ply.to_file(crsName)  # Write new shapefile \n",
    "    # Read and process shapefile\n",
    "    with rasterio.open(tiffile) as geotiff:\n",
    "        with fiona.open(crsName, \"r\") as shapefile:\n",
    "            shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "            for index, shape in enumerate(shapes):\n",
    "                try:\n",
    "                    out_image, out_transform = rasterio.mask.mask(geotiff, [shape], crop=True)                 \n",
    "                    # Extract desired columns from the clipped shapefile\n",
    "                    clipped_shapefile = ply.clip(gpd.GeoDataFrame(geometry=[shape], crs=ply.crs))\n",
    "                    extracted_data = clipped_shapefile[desired_columns]                   \n",
    "                    # Extract StandID as integer and append to stand_id list\n",
    "                    stand_id_value = int(clipped_shapefile['StandID'].values[0])\n",
    "                    stand_id.append(stand_id_value)                  \n",
    "                    # Convert the extracted data to a dictionary\n",
    "                    extracted_data_dict_list = extracted_data.to_dict(orient='records')\n",
    "                    # Optionally, convert the list of dictionaries into a single dictionary if needed\n",
    "                    # For example, if you want a dictionary with column names as keys and lists of values as values:\n",
    "                    extracted_data_dict = extracted_data.to_dict(orient='list')\n",
    "                    # Call to_csv function to create and save the CSV file\n",
    "                    to_csv(out_image, csv_folder, index, extracted_data_dict, csv_files, stand_id[-1])\n",
    "                except Exception as ex:\n",
    "                    print(f\"Error processing shape {index}: {str(ex)}\")\n",
    "                    traceback.print_exc()  # Print the full traceback\n",
    "                    print(\"\\n\")\n",
    "                    print(\"\\n\")\n",
    "                    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 14, 15, 16, 2016, 1978, 1993, 1995, 2000, 2012, 2016]\n"
     ]
    }
   ],
   "source": [
    "print(stand_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_11.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_12.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_13.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_14.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_15.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_16.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_2016.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_1978.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_1993.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_1995.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_2000.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_2012.csv\n",
      "c:\\Users\\raun9583\\Downloads\\new_model_test\\source/csv_files\\csv_for_stand_2016.csv\n"
     ]
    }
   ],
   "source": [
    "for item  in csv_files:\n",
    "    print(item)\n",
    "    # print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in csv_files:\n",
    "#     print(f\"CSV File: {item}\")\n",
    "predictions_and_stats_list = []\n",
    "# Navigate to the 'java' directory (adjust path as needed)\n",
    "cwd = os.getcwd()  # Assuming cwd is defined somewhere earlier\n",
    "JAVA_SERVICE_PATH = os.path.join(cwd, 'source/java')\n",
    "H2O_GENMODEL_JAR_PATH = os.path.join(JAVA_SERVICE_PATH, 'h2o-genmodel.jar')\n",
    "GSON_JAR_PATH = os.path.join(JAVA_SERVICE_PATH, 'gson-2.8.8.jar')\n",
    "MAIN_JAVA_FILE_PATH = os.path.join(JAVA_SERVICE_PATH, 'main1.java')\n",
    "\n",
    "\n",
    "# Check if Java files and JARs exist\n",
    "if not os.path.exists(H2O_GENMODEL_JAR_PATH):\n",
    "    raise FileNotFoundError(f\"JAR file not found: {H2O_GENMODEL_JAR_PATH}\")\n",
    "if not os.path.exists(GSON_JAR_PATH):\n",
    "    raise FileNotFoundError(f\"JAR file not found: {GSON_JAR_PATH}\")\n",
    "if not os.path.exists(MAIN_JAVA_FILE_PATH):\n",
    "    raise FileNotFoundError(f\"Java file not found: {MAIN_JAVA_FILE_PATH}\")\n",
    "\n",
    "# Use the correct classpath separator\n",
    "classpath_separator = os.pathsep\n",
    "classpath = f'.{classpath_separator}{H2O_GENMODEL_JAR_PATH}{classpath_separator}{GSON_JAR_PATH}'\n",
    "\n",
    "try:\n",
    "    for item in csv_files:\n",
    "        # Compile the Java code\n",
    "        compile_command = ['javac', '-cp', classpath, 'main1.java']\n",
    "        subprocess.run(compile_command, cwd=JAVA_SERVICE_PATH, check=True)\n",
    "        # Execute the Java code and capture the output\n",
    "        run_command = ['java', '-cp', classpath, 'main1', item]\n",
    "        output = subprocess.check_output(run_command, cwd=JAVA_SERVICE_PATH)\n",
    "        output_str = output.decode('utf-8')\n",
    "        # Process the output (assuming it's JSON)\n",
    "        predictions_and_stats = json.loads(output_str)\n",
    "        # Round statistical metrics to the nearest integer\n",
    "        rounded_predictions = {metric: round(value) for metric, value in predictions_and_stats.items()}\n",
    "        predictions_and_stats_list.append(rounded_predictions)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error executing Java code: {e}\")\n",
    "    raise RuntimeError('Error executing Java code') from e  # Handle error as needed\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON output from Java: {e}\")\n",
    "    raise RuntimeError('Error decoding JSON output from Java') from e  # Handle JSON decoding error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(predictions_and_stats_list)\n",
    "df['StandId'] = [items for items in stand_id]\n",
    "# Adjust display options to show full content of columns\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>highestValue</th>\n",
       "      <th>lowestValue</th>\n",
       "      <th>StandId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>337</td>\n",
       "      <td>343</td>\n",
       "      <td>330</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330</td>\n",
       "      <td>330</td>\n",
       "      <td>332</td>\n",
       "      <td>343</td>\n",
       "      <td>330</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>330</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>355</td>\n",
       "      <td>330</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>349</td>\n",
       "      <td>360</td>\n",
       "      <td>340</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>359</td>\n",
       "      <td>384</td>\n",
       "      <td>340</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>337</td>\n",
       "      <td>343</td>\n",
       "      <td>330</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>330</td>\n",
       "      <td>330</td>\n",
       "      <td>332</td>\n",
       "      <td>343</td>\n",
       "      <td>330</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>335</td>\n",
       "      <td>396</td>\n",
       "      <td>330</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>330</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>349</td>\n",
       "      <td>360</td>\n",
       "      <td>340</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>359</td>\n",
       "      <td>384</td>\n",
       "      <td>340</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mode  median  mean  highestValue  lowestValue  StandId\n",
       "0    343     343   337           343          330       11\n",
       "1    333     333   333           333          333       12\n",
       "2    330     330   332           343          330       13\n",
       "3    333     333   333           333          330       14\n",
       "4    333     333   333           355          330       15\n",
       "5    351     351   349           360          340       16\n",
       "6    356     356   359           384          340     2016\n",
       "7    343     343   337           343          330     1978\n",
       "8    330     330   332           343          330     1993\n",
       "9    333     333   335           396          330     1995\n",
       "10   333     333   333           333          330     2000\n",
       "11   351     351   349           360          340     2012\n",
       "12   356     356   359           384          340     2016"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = os.path.join(cwd,'result/result.csv')\n",
    "df.to_csv(result_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
